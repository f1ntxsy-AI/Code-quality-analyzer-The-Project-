"""
–ì–ª–∞–≤–Ω—ã–π –º–æ–¥—É–ª—å CLI –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–¥–∞
"""
import sys
import io

# –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –¥–ª—è Windows
if sys.platform == 'win32':
    try:
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')
    except:
        pass  # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –∫–æ–¥–∏—Ä–æ–≤–∫—É

import argparse
import json
from pathlib import Path
from metrics import CodeMetrics
from report_generator import ReportGenerator


def safe_print(text):
    """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –≤—ã–≤–æ–¥ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —ç–º–æ–¥–∑–∏ –¥–ª—è Windows"""
    try:
        print(text)
    except UnicodeEncodeError:
        # –ï—Å–ª–∏ –∫–æ–Ω—Å–æ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç Unicode - —É–±–∏—Ä–∞–µ–º —ç–º–æ–¥–∑–∏
        clean_text = text.encode('ascii', 'ignore').decode('ascii')
        print(clean_text)


def analyze_file(filepath: str, output_dir: str = "reports", output_format: str = "text") -> None:
    """
    –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞ —Å –∫–æ–¥–æ–º

    Args:
        filepath: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        output_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç—á—ë—Ç–æ–≤
        output_format: —Ñ–æ—Ä–º–∞—Ç –æ—Ç—á—ë—Ç–∞ (text, json, markdown, all)
    """
    # –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            code = f.read()
    except FileNotFoundError:
        safe_print(f"‚ùå Error: File not found: {filepath}")
        sys.exit(1)
    except Exception as e:
        safe_print(f"‚ùå Error reading file: {e}")
        sys.exit(1)

    filename = Path(filepath).name

    safe_print(f"üîç Analyzing: {filename}")
    safe_print("=" * 70)

    # –ê–Ω–∞–ª–∏–∑ –∫–æ–¥–∞
    try:
        analyzer = CodeMetrics(code, filename)
        metrics = analyzer.analyze()
    except ValueError as e:
        safe_print(f"‚ùå Error analyzing code: {e}")
        sys.exit(1)

    # –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –æ—Ç—á—ë—Ç–æ–≤
    output_path_dir = Path(output_dir)
    output_path_dir.mkdir(parents=True, exist_ok=True)

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–æ–≤
    base_name = Path(filename).stem

    # TEXT –æ—Ç—á—ë—Ç
    if output_format in ["text", "all"]:
        report = ReportGenerator.generate_text_report(metrics)
        print(report)

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª
        txt_path = output_path_dir / f"{base_name}_report.txt"
        with open(txt_path, 'w', encoding='utf-8') as f:
            f.write(report)
        safe_print(f"\nüíæ Text report saved: {txt_path}")

    # JSON –æ—Ç—á—ë—Ç
    if output_format in ["json", "all"]:
        json_path = output_path_dir / f"{base_name}_report.json"

        # ReportGenerator.generate_json_report –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ, –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç
        json_data = ReportGenerator.generate_json_report(metrics)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∞–º–∏
        with open(json_path, 'w', encoding='utf-8') as f:
            if isinstance(json_data, str):
                f.write(json_data)
            else:
                json.dump(json_data, f, indent=2, ensure_ascii=False)

        safe_print(f"üíæ JSON report saved: {json_path}")

    # Markdown –æ—Ç—á—ë—Ç
    if output_format in ["markdown", "all"]:
        md_path = output_path_dir / f"{base_name}_report.md"

        # ReportGenerator.generate_markdown_report –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç, –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç
        md_content = ReportGenerator.generate_markdown_report(metrics)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∞–º–∏
        with open(md_path, 'w', encoding='utf-8') as f:
            f.write(md_content)

        safe_print(f"üíæ Markdown report saved: {md_path}")


def analyze_directory(directory: str, output_dir: str = "reports", output_format: str = "text") -> None:
    """
    –ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö Python —Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏

    Args:
        directory: –ø—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        output_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç—á—ë—Ç–æ–≤
        output_format: —Ñ–æ—Ä–º–∞—Ç –æ—Ç—á—ë—Ç–∞
    """
    dir_path = Path(directory)

    if not dir_path.exists():
        safe_print(f"‚ùå Error: Directory not found: {directory}")
        sys.exit(1)

    python_files = list(dir_path.glob("*.py"))

    if not python_files:
        safe_print(f"‚ö†Ô∏è  No Python files found in: {directory}")
        sys.exit(0)

    safe_print(f"üìÅ Found {len(python_files)} Python file(s) in {directory}")
    safe_print("=" * 70)

    for filepath in python_files:
        safe_print(f"\n{'=' * 70}")
        analyze_file(str(filepath), output_dir, output_format)


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è CLI"""
    parser = argparse.ArgumentParser(
        description='Code Quality Analyzer - Analyze Python code quality'
    )

    parser.add_argument(
        '--file',
        type=str,
        help='Path to Python file to analyze'
    )

    parser.add_argument(
        '--directory',
        type=str,
        help='Path to directory with Python files'
    )

    parser.add_argument(
        '--output-dir',
        type=str,
        default='reports',
        help='Output directory for reports (default: reports)'
    )

    parser.add_argument(
        '--format',
        type=str,
        choices=['text', 'json', 'markdown', 'all'],
        default='text',
        help='Report format: text, json, markdown, or all (default: text)'
    )

    args = parser.parse_args()

    if not args.file and not args.directory:
        parser.print_help()
        safe_print("\n‚ùå Error: Please specify --file or --directory")
        sys.exit(1)

    if args.file:
        analyze_file(args.file, args.output_dir, args.format)
    elif args.directory:
        analyze_directory(args.directory, args.output_dir, args.format)


if __name__ == '__main__':
    main()
